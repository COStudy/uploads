save(data,file = "data/all.Rdata")
mapNames = mapNames("china")[-c(24,33,34)]
string = readLines("index.Rmd", encoding="UTF-8") %>% paste(collapse = "\n")
# modelList = c("ix25", "ix35", "朗动", "领动","名图","瑞纳","途胜")
modelList = mapNames
sapply(modelList , function(x){
content = tmcn::toPinyin(x,capitalize = T)
tmpString = gsub( "content", content, string, fixed = T)
tmpString = gsub( "北京", x, string, fixed = T)
iconv(tmpString, "UTF-8", "UTF-8")
writeLines(tmpString,paste0(x,".Rmd"),useBytes = T)
rmarkdown::render(paste0(x,".Rmd"),
## .html 换购
## .2html 增购
## .3html 换购增购一起来
output_file = paste0("html/", x, ".html") ,
# output_file = paste0("html/", x, "2.html") ,
# output_file = paste0("html/", x, "3.html") ,
encoding="UTF-8")
unlink(paste0(x,".Rmd"))
return(NULL)
})
# fileNames = dir("html",full.names = T)[grepl(pattern = "html", dir("html"))]
# sapply(fileNames, function(x){
#   file.copy(x, "html/1.html")
#   output = sub(pattern = "html",
#                 replacement = "output",
#                 x)
#   output = sub(pattern = "html",
#                 replacement = "png",
#                 output)
#   webshot::webshot('html/1.html',
#                    output,
#                    vwidth = 1200, vheight = 800, delay =10)
#   unlink("html/1.html")
# })
mapNames("china")[-c(24,33,34)]
mapNames("china")
library(RODBC)
library(dplyr)
library(jsonlite)
library(REmap)
library(tmcn)
Sys.setlocale("LC_CTYPE","chs")
con = odbcConnect("cn04")
query = "select * from [xuhao].[dbo].[registration_2017_province_month]
where Registermonth='04'"
# query = iconv(query,"UTF-8","GB2312")
data = sqlQuery(con,query)
close(con)
save(data,file = "data/all.Rdata")
mapNames = mapNames("china")[-c(29,33,34)]
string = readLines("index.Rmd", encoding="UTF-8") %>% paste(collapse = "\n")
# modelList = c("ix25", "ix35", "朗动", "领动","名图","瑞纳","途胜")
modelList = mapNames
sapply(modelList , function(x){
content = tmcn::toPinyin(x,capitalize = T)
tmpString = gsub( "content", content, string, fixed = T)
tmpString = gsub( "北京", x, string, fixed = T)
iconv(tmpString, "UTF-8", "UTF-8")
writeLines(tmpString,paste0(x,".Rmd"),useBytes = T)
rmarkdown::render(paste0(x,".Rmd"),
## .html 换购
## .2html 增购
## .3html 换购增购一起来
output_file = paste0("html/", x, ".html") ,
# output_file = paste0("html/", x, "2.html") ,
# output_file = paste0("html/", x, "3.html") ,
encoding="UTF-8")
unlink(paste0(x,".Rmd"))
return(NULL)
})
# fileNames = dir("html",full.names = T)[grepl(pattern = "html", dir("html"))]
# sapply(fileNames, function(x){
#   file.copy(x, "html/1.html")
#   output = sub(pattern = "html",
#                 replacement = "output",
#                 x)
#   output = sub(pattern = "html",
#                 replacement = "png",
#                 output)
#   webshot::webshot('html/1.html',
#                    output,
#                    vwidth = 1200, vheight = 800, delay =10)
#   unlink("html/1.html")
# })
library(flexdashboard)
library(knitr)
library(dplyr)
library(shiny)
library(recharts)
library(DT)
load("data/all.Rdata")
load("data/hyundaiAdd.Rdata")
###important
model = "北京"
a(href="../index.html")
a(href="../index.html")
a(href="../index.html",'Back to Selector')
library(RODBC)
library(dplyr)
library(jsonlite)
library(REmap)
library(tmcn)
Sys.setlocale("LC_CTYPE","chs")
con = odbcConnect("cn04")
query = "select * from [xuhao].[dbo].[registration_2017_province_month]
where Registermonth='04'"
# query = iconv(query,"UTF-8","GB2312")
data = sqlQuery(con,query)
close(con)
save(data,file = "data/all.Rdata")
mapNames = mapNames("china")[-c(29,33,34)]
string = readLines("index.Rmd", encoding="UTF-8") %>% paste(collapse = "\n")
# modelList = c("ix25", "ix35", "朗动", "领动","名图","瑞纳","途胜")
modelList = mapNames
sapply(modelList , function(x){
content = tmcn::toPinyin(x,capitalize = T)
tmpString = gsub( "Beijing", content, string, fixed = T)
tmpString = gsub( "北京", x, string, fixed = T)
iconv(tmpString, "UTF-8", "UTF-8")
writeLines(tmpString,paste0(x,".Rmd"),useBytes = T)
rmarkdown::render(paste0(x,".Rmd"),
## .html 换购
## .2html 增购
## .3html 换购增购一起来
output_file = paste0("html/", x, ".html") ,
# output_file = paste0("html/", x, "2.html") ,
# output_file = paste0("html/", x, "3.html") ,
encoding="UTF-8")
unlink(paste0(x,".Rmd"))
return(NULL)
})
# fileNames = dir("html",full.names = T)[grepl(pattern = "html", dir("html"))]
# sapply(fileNames, function(x){
#   file.copy(x, "html/1.html")
#   output = sub(pattern = "html",
#                 replacement = "output",
#                 x)
#   output = sub(pattern = "html",
#                 replacement = "png",
#                 output)
#   webshot::webshot('html/1.html',
#                    output,
#                    vwidth = 1200, vheight = 800, delay =10)
#   unlink("html/1.html")
# })
setwd("html/")
file.rename(paste0(c("安徽", "北京", "福建", "甘肃", "广东",
"广西", "贵州", "海南", "河北", "河南", "黑龙江",
"湖北", "湖南", "吉林", "江苏", "江西", "辽宁",
"内蒙古", "宁夏", "青海", "山东", "山西", "陕西",
"上海", "四川", "天津", "西藏", "新疆", "云南",
"浙江", "重庆"),".html"),
paste0(c(0:30),".html"))
library(RODBC)
library(dplyr)
library(jsonlite)
library(REmap)
library(tmcn)
Sys.setlocale("LC_CTYPE","chs")
con = odbcConnect("cn04")
query = "select * from [xuhao].[dbo].[registration_2017_province_month]
where Registermonth='04'"
# query = iconv(query,"UTF-8","GB2312")
data = sqlQuery(con,query)
close(con)
save(data,file = "data/all.Rdata")
mapNames = mapNames("china")[-c(29,33,34)]
string = readLines("index.Rmd", encoding="UTF-8") %>% paste(collapse = "\n")
# modelList = c("ix25", "ix35", "朗动", "领动","名图","瑞纳","途胜")
modelList = mapNames
sapply(modelList , function(x){
content = tmcn::toPinyin(x,capitalize = T)
tmpString = gsub( "Beijing", content, string, fixed = T)
tmpString = gsub( "北京", x, tmpString, fixed = T)
iconv(tmpString, "UTF-8", "UTF-8")
writeLines(tmpString,paste0(x,".Rmd"),useBytes = T)
rmarkdown::render(paste0(x,".Rmd"),
## .html 换购
## .2html 增购
## .3html 换购增购一起来
output_file = paste0("html/", x, ".html") ,
# output_file = paste0("html/", x, "2.html") ,
# output_file = paste0("html/", x, "3.html") ,
encoding="UTF-8")
unlink(paste0(x,".Rmd"))
return(NULL)
})
# fileNames = dir("html",full.names = T)[grepl(pattern = "html", dir("html"))]
# sapply(fileNames, function(x){
#   file.copy(x, "html/1.html")
#   output = sub(pattern = "html",
#                 replacement = "output",
#                 x)
#   output = sub(pattern = "html",
#                 replacement = "png",
#                 output)
#   webshot::webshot('html/1.html',
#                    output,
#                    vwidth = 1200, vheight = 800, delay =10)
#   unlink("html/1.html")
# })
setwd("html/")
file.rename(paste0(c("安徽", "北京", "福建", "甘肃", "广东",
"广西", "贵州", "海南", "河北", "河南", "黑龙江",
"湖北", "湖南", "吉林", "江苏", "江西", "辽宁",
"内蒙古", "宁夏", "青海", "山东", "山西", "陕西",
"上海", "四川", "天津", "西藏", "新疆", "云南",
"浙江", "重庆"),".html"),
paste0(c(0:30),".html"))
setwd("../")
library(RODBC)
library(dplyr)
library(jsonlite)
library(REmap)
library(tmcn)
Sys.setlocale("LC_CTYPE","chs")
con = odbcConnect("cn04")
query = "select * from [xuhao].[dbo].[registration_2017_province_month]
where Registermonth='04'"
# query = iconv(query,"UTF-8","GB2312")
data = sqlQuery(con,query)
close(con)
save(data,file = "data/all.Rdata")
mapNames = mapNames("china")[-c(29,33,34)]
string = readLines("index.Rmd", encoding="UTF-8") %>% paste(collapse = "\n")
# modelList = c("ix25", "ix35", "朗动", "领动","名图","瑞纳","途胜")
modelList = mapNames
sapply(modelList , function(x){
content = tmcn::toPinyin(x,capitalize = T)
tmpString = gsub( "Beijing", content, string, fixed = T)
tmpString = gsub( "北京", x, tmpString, fixed = T)
iconv(tmpString, "UTF-8", "UTF-8")
writeLines(tmpString,paste0(x,".Rmd"),useBytes = T)
rmarkdown::render(paste0(x,".Rmd"),
## .html 换购
## .2html 增购
## .3html 换购增购一起来
output_file = paste0("html/", x, ".html") ,
# output_file = paste0("html/", x, "2.html") ,
# output_file = paste0("html/", x, "3.html") ,
encoding="UTF-8")
unlink(paste0(x,".Rmd"))
return(NULL)
})
# fileNames = dir("html",full.names = T)[grepl(pattern = "html", dir("html"))]
# sapply(fileNames, function(x){
#   file.copy(x, "html/1.html")
#   output = sub(pattern = "html",
#                 replacement = "output",
#                 x)
#   output = sub(pattern = "html",
#                 replacement = "png",
#                 output)
#   webshot::webshot('html/1.html',
#                    output,
#                    vwidth = 1200, vheight = 800, delay =10)
#   unlink("html/1.html")
# })
setwd("html/")
file.rename(paste0(c("安徽", "北京", "福建", "甘肃", "广东",
"广西", "贵州", "海南", "河北", "河南", "黑龙江",
"湖北", "湖南", "吉林", "江苏", "江西", "辽宁",
"内蒙古", "宁夏", "青海", "山东", "山西", "陕西",
"上海", "四川", "天津", "西藏", "新疆", "云南",
"浙江", "重庆"),".html"),
paste0(c(0:30),".html"))
setwd("../")
toPinyin(x,capitalize = T)
toPinyin(x)
toPinyin("奥德赛")
toPinyin("奥德赛",captalize=T)
toPinyin("奥德赛",capitalize=T)
library(Hmisc)
library(RODBC)
library(dplyr)
library(jsonlite)
library(REmap)
library(tmcn)
library(Hmisc)
Sys.setlocale("LC_CTYPE","chs")
con = odbcConnect("cn04")
query = "select * from [xuhao].[dbo].[registration_2017_province_month]
where Registermonth='04'"
# query = iconv(query,"UTF-8","GB2312")
data = sqlQuery(con,query)
close(con)
save(data,file = "data/all.Rdata")
mapNames = mapNames("china")[-c(29,33,34)]
string = readLines("index.Rmd", encoding="UTF-8") %>% paste(collapse = "\n")
# modelList = c("ix25", "ix35", "朗动", "领动","名图","瑞纳","途胜")
modelList = mapNames
sapply(modelList , function(x){
content = capitalize(toPinyin(x))
tmpString = gsub( "Beijing", content, string, fixed = T)
tmpString = gsub( "北京", x, tmpString, fixed = T)
iconv(tmpString, "UTF-8", "UTF-8")
writeLines(tmpString,paste0(x,".Rmd"),useBytes = T)
rmarkdown::render(paste0(x,".Rmd"),
## .html 换购
## .2html 增购
## .3html 换购增购一起来
output_file = paste0("html/", x, ".html") ,
# output_file = paste0("html/", x, "2.html") ,
# output_file = paste0("html/", x, "3.html") ,
encoding="UTF-8")
unlink(paste0(x,".Rmd"))
return(NULL)
})
# fileNames = dir("html",full.names = T)[grepl(pattern = "html", dir("html"))]
# sapply(fileNames, function(x){
#   file.copy(x, "html/1.html")
#   output = sub(pattern = "html",
#                 replacement = "output",
#                 x)
#   output = sub(pattern = "html",
#                 replacement = "png",
#                 output)
#   webshot::webshot('html/1.html',
#                    output,
#                    vwidth = 1200, vheight = 800, delay =10)
#   unlink("html/1.html")
# })
setwd("html/")
file.rename(paste0(c("安徽", "北京", "福建", "甘肃", "广东",
"广西", "贵州", "海南", "河北", "河南", "黑龙江",
"湖北", "湖南", "吉林", "江苏", "江西", "辽宁",
"内蒙古", "宁夏", "青海", "山东", "山西", "陕西",
"上海", "四川", "天津", "西藏", "新疆", "云南",
"浙江", "重庆"),".html"),
paste0(c(0:30),".html"))
setwd("../")
list = jsonlite::fromJSON("https://raw.githubusercontent.com/Lchiffon/cosx.org/aloglia/index.json")
URL = sub("cosx.org","cos.name",list$url)
outputList = list()
i =1
content = try(readLines(URL[i], encoding = 'UTF-8'))
read_html(content)
library(rvest)
read_html(content)
read_html(content) %>% html_nodes("img")
class(content)
writeLines(content, "tmp.html")
read_html("tmp.html") %>% html_nodes("img")
read_html("tmp.html") %>% html_nodes("img") %>% html_attr('src')
read_html("tmp.html") %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name/wp-content",.,value = T)
list = jsonlite::fromJSON("https://raw.githubusercontent.com/Lchiffon/cosx.org/aloglia/index.json")
URL = sub("cosx.org","cos.name",list$url)
outputList = list()
for(i in 1:length(URL)){
print(URL[i])
content = try(readLines(URL[i], encoding = 'UTF-8'))
writeLines(content, "tmp.html")
tmpImgURL = read_html("tmp.html") %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
outputList = append(outputList, list(str = tmpImgURL))
}
outputList
i
tmpImgURL = read_html("tmp.html") %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
read_html("tmp.html") %>% html_nodes("img")
content
read_html("tmp.html")
?
XML_PARSE_HUGE
??XML_PARSE_HUGE
getwd()
?read_html
tmpImgURL = read_html("tmp.html", options = HUGE) %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
HUGE=524288
tmpImgURL = read_html("tmp.html", options = HUGE) %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
tmpImgURL
outputList = append(outputList, list(str = tmpImgURL))
for(i in 348:length(URL)){
print(URL[i])
content = try(readLines(URL[i], encoding = 'UTF-8'))
writeLines(content, "tmp.html")
tmpImgURL = read_html("tmp.html") %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
outputList = append(outputList, list(str = tmpImgURL))
}
list = jsonlite::fromJSON("https://raw.githubusercontent.com/Lchiffon/cosx.org/aloglia/index.json")
# URL = sub("cosx.org","cos.name",list$url)
outputList = list()
for(i in 1:length(URL)){
print(URL[i])
content = try(readLines(URL[i], encoding = 'UTF-8'))
writeLines(content, "tmp.html")
tmpImgURL = read_html("tmp.html") %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
outputList = append(outputList, list(str = tmpImgURL))
}
URL = list$url
outputList = list()
for(i in 1:length(URL)){
print(URL[i])
content = try(readLines(URL[i], encoding = 'UTF-8'))
writeLines(content, "tmp.html")
tmpImgURL = read_html("tmp.html") %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
outputList = append(outputList, list(str = tmpImgURL))
}
warnings()
do.call(outputList,c)
do.call(c, outputList)
downloadURL = do.call(c, outputList)
downloadURL = do.call(c, outputList) %>% unique
setwd("D:/git/uploads/")
?download.file
?downloadLink
downloadURL = do.call(c, outputList) %>% unique %>% iconv("UTF-8","UTF-8")
downloadURL
downloadURL = do.call(c, outputList) %>% unique %>% iconv("UTF-8","GBK")
downloadURL
downloadURL = do.call(c, outputList) %>% unique %>% iconv("GBK","UTF-8")
downloadURL
downloadURL = do.call(c, outputList) %>% unique
downloadURL
URL = list$url
outputList = list()
for(i in 1:length(URL)){
print(URL[i])
content = try(readLines(URL[i], encoding = 'UTF-8'))
writeLines(content, "tmp.html", useBytes = T)
tmpImgURL = read_html("tmp.html", encoding='UTF-8') %>% html_nodes("img") %>% html_attr('src') %>%
grep("cos.name",.,value = T)
outputList = append(outputList, list(str = tmpImgURL))
}
downloadURL = do.call(c, outputList) %>% unique
downloadURL
setwd("D:/git/uploads/")
downloadURL = do.call(c, outputList) %>% unique %>% grep("https://cos.name/wp-content/",.,value = T)
downloadURL = do.call(c, outputList) %>% unique %>% grep("https://cos.name/",.,value = T)
downloadURL = do.call(c, outputList) %>% unique %>% grep("http://cos.name/",.,value = T)
downloadURL = do.call(c, outputList) %>% unique
downloadURL = do.call(c, outputList) %>% unique %>% grep("https://cos.name/",.,value = T)
downloadURL2 = do.call(c, outputList) %>% unique
setdiff(downloadURL,downloadURL@)
setdiff(downloadURL,downloadURL2)
setdiff(downloadURL2,downloadURL)
fileNames = downloadURL %>% gsub("https://cos.name/","./",.)
fileNames
setwd("D:/git/uploads/")
download.file(downloadURL[1],fileNames[1] )
dirNames = sapply(filNames, function(x){
out = strsplit(x,"/")
n = length(out)
return(paste0(out, collapse = "/"))
})
dirNames = sapply(fileNames, function(x){
out = strsplit(x,"/")
n = length(out)
return(paste0(out, collapse = "/"))
})
dirNames
dirNames[1]
dirNames = sapply(fileNames, function(x){
out = strsplit(x,"/")
n = length(out)
return(paste0(out[-(n-1)], collapse = "/"))
})
dirNames[1]
x = fileNames[1]
x
out = strsplit(x,"/")
n = length(out)
out
dirNames = sapply(fileNames, function(x){
out = strsplit(x,"/")
n = length(out)
return(paste0(out[[1]][-(n-1)], collapse = "/"))
})
dirNames[1]
out = strsplit(x,"/")
n = length(out)
out[[1]][-(n-1)]
out[[1]]
dirNames = sapply(fileNames, function(x){
out = strsplit(x,"/")[[1]]
n = length(out)
return(paste0(out[-(n-1)], collapse = "/"))
})
dirNames[1]
out = strsplit(x,"/")[[1]]
n = length(out)
out[-(n-1)]
dirNames = sapply(fileNames, function(x){
out = strsplit(x,"/")[[1]]
n = length(out)
return(paste0(out[-n], collapse = "/"))
})
dirNames[1]
setwd("D:/git/uploads/")
i =1
if(!dir.exists(dirNames[i]))
dir.create(dirNames[i])
dir.create(dirNames[i],recursive = T)
download.file(downloadURL[1],fileNames[1],)
download.file(downloadURL[1],fileNames[1],"wb")
download.file(downloadURL[1],fileNames[1],"curl")
for(i in 1: length(downloadURL)){
print(downloadURL[i])
if(!dir.exists(dirNames[i]))
dir.create(dirNames[i],recursive = T)
download.file(downloadURL[i],fileNames[i],"curl")
}
save(list, downloadURL, file = "local.Rdata")
